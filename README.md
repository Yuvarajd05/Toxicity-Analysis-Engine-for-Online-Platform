Toxicity-Analysis-Engine-for-Online-Platform

A machine learning engine that detects and classifies toxic content in online text using a fine-tuned BERT model.

ğŸ“Œ Features

âœ… Classifies input text into six bullying categories:

toxic

severe_toxic

obscene

threat

insult

identity_hate

ğŸ§  Fine-tuned BERT (bert-base-uncased)

ğŸ’¬ Supports web UI and chat interface

ğŸŒ RESTful API using Flask + CORS

ğŸ“ˆ Trained on 150,000+ social media comments

ğŸ“‚ Project Structure
Toxicity-Analysis-Engine-for-Online-Platform/
â”œâ”€â”€ app.py                # Flask backend with BERT model
â”œâ”€â”€ Bert.hdfs             # Fine-tuned BERT model directory
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ templates/            # HTML frontend (if applicable)
â”œâ”€â”€ static/               # CSS/JS assets (optional)
â””â”€â”€ README.md             # Project documentation

âš™ï¸ Installation

Clone the repository

git clone https://github.com/your-username/Toxicity-Analysis-Engine-for-Online-Platform.git
cd Toxicity-Analysis-Engine-for-Online-Platform


Download fine-tuned model (Bert.hdfs)
Download the folder containing config.json and dataset file:
Google Drive Link

Place Bert.hdfs in the project root directory.

Set up a virtual environment (optional but recommended)

python -m venv venv
source venv/bin/activate      # On Windows: venv\Scripts\activate


Install dependencies

pip install -r requirements.txt

â–¶ï¸ Running the App
python app.py


Server will start at http://localhost:5000

ğŸ§ª API Usage

Endpoint: /process_text

Method: POST

Content-Type: application/json

ğŸ”¸ Sample Request
{
  "input_text": "You're such an idiot and a complete failure!"
}

ğŸ”¸ Sample Response
{
  "original_text": "You're such an idiot and a complete failure!",
  "predictedLables": ["toxic", "insult"],
  "status": 2
}

ğŸ§  Model Details

Architecture: BERT (bert-base-uncased)

Task: Multi-label text classification

Dataset: 1.5 lakh annotated social media comments

Output: 6-dimensional binary vector

Framework: PyTorch + Transformers

ğŸ“ˆ Evaluation Metrics

The model was trained and evaluated using:

Accuracy

Precision

Recall

F1 Score

ğŸ“š Future Enhancements

Add styled frontend UI

Enable file upload or batch detection

Add login/authentication for moderation dashboards

Visualize toxicity trends with charts

ğŸ¤ Acknowledgements

Hugging Face Transformers

Jigsaw Toxic Comment Dataset

Flask & PyTorch communities

ğŸ“œ License

This project is licensed under the MIT License.
